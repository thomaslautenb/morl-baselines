{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import mo_gymnasium as mo_gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import wandb\n",
    "from torch import nn\n",
    "from morl_baselines.common.networks import mlp\n",
    "from morl_baselines.common.evaluation import log_episode_info\n",
    "from morl_baselines.common.morl_algorithm import MOPolicy\n",
    "from morl_baselines.single_policy.ser import mo_ppo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the environment and parameters\n",
    "env_id = \"mo-halfcheetah-v4\"  # Replace with the desired MO-Gymnasium environment\n",
    "seed = 42\n",
    "gamma = 0.995\n",
    "steps_per_iteration = 2048\n",
    "num_minibatches = 32\n",
    "update_epochs = 10\n",
    "learning_rate = 3e-4\n",
    "clip_coef = 0.2\n",
    "ent_coef = 0.0\n",
    "vf_coef = 0.5\n",
    "max_grad_norm = 0.5\n",
    "gae_lambda = 0.95\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "weights = np.array([0.5, 0.5])  # Example weights for objectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\anaconda3\\envs\\MORL_baseline\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\thoma\\anaconda3\\envs\\MORL_baseline\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\thoma\\anaconda3\\envs\\MORL_baseline\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.is_vector_env to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_vector_env` for environment variables or `env.get_wrapper_attr('is_vector_env')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "num_envs = 8\n",
    "# Create vectorized environments\n",
    "env_fns = [mo_ppo.make_env(env_id, seed + i, i, \"run_name\", gamma) for i in range(8)]\n",
    "envs = gym.vector.SyncVectorEnv(env_fns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncVectorEnv(8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the networks\n",
    "obs_shape = envs.single_observation_space.shape\n",
    "action_shape = envs.single_action_space.shape\n",
    "# Get the reward dimension from the environment\n",
    "temp_env = mo_ppo.make_env(env_id, seed, 0, \"run_name\", gamma)()\n",
    "reward_dim = temp_env.reward_space.shape[0]\n",
    "\n",
    "networks = mo_ppo.MOPPONet(obs_shape, action_shape, reward_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize MOPPO\n",
    "moppo = mo_ppo.MOPPO(\n",
    "    id=0,\n",
    "    networks=networks,\n",
    "    weights=weights,\n",
    "    envs=envs,\n",
    "    log=True,\n",
    "    steps_per_iteration=steps_per_iteration,\n",
    "    num_minibatches=num_minibatches,\n",
    "    update_epochs=update_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    gamma=gamma,\n",
    "    anneal_lr=False,\n",
    "    clip_coef=clip_coef,\n",
    "    ent_coef=ent_coef,\n",
    "    vf_coef=vf_coef,\n",
    "    clip_vloss=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    norm_adv=True,\n",
    "    target_kl=None,\n",
    "    gae=True,\n",
    "    gae_lambda=gae_lambda,\n",
    "    device=device,\n",
    "    seed=seed,\n",
    "    rng=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt-lautenbacher\u001b[0m (\u001b[33mthomas_lautenbacher\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\thoma\\MA\\morl-baselines\\examples\\wandb\\run-20240606_144229-tbyoluxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thomas_lautenbacher/moppo_example/runs/tbyoluxs' target=\"_blank\">summer-river-14</a></strong> to <a href='https://wandb.ai/thomas_lautenbacher/moppo_example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thomas_lautenbacher/moppo_example' target=\"_blank\">https://wandb.ai/thomas_lautenbacher/moppo_example</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thomas_lautenbacher/moppo_example/runs/tbyoluxs' target=\"_blank\">https://wandb.ai/thomas_lautenbacher/moppo_example/runs/tbyoluxs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.5000], dtype=torch.float64)\n",
      "SPS: 1497\n",
      "tensor([[-0.0016, -0.0266],\n",
      "        [ 0.0083, -0.0305],\n",
      "        [ 0.0120, -0.0238],\n",
      "        [-0.0206, -0.0273],\n",
      "        [-0.1042, -0.0269],\n",
      "        [ 0.0302, -0.0296],\n",
      "        [ 0.0797, -0.0264],\n",
      "        [-0.0963, -0.0326]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>charts/SPS</td><td>▁</td></tr><tr><td>charts_0/learning_rate</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁</td></tr><tr><td>losses_0/approx_kl</td><td>▁</td></tr><tr><td>losses_0/clipfrac</td><td>▁</td></tr><tr><td>losses_0/entropy</td><td>▁</td></tr><tr><td>losses_0/explained_variance</td><td>▁</td></tr><tr><td>losses_0/old_approx_kl</td><td>▁</td></tr><tr><td>losses_0/policy_loss</td><td>▁</td></tr><tr><td>losses_0/value_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>charts/SPS</td><td>1496</td></tr><tr><td>charts_0/learning_rate</td><td>0.0003</td></tr><tr><td>global_step</td><td>16384</td></tr><tr><td>losses_0/approx_kl</td><td>0.00727</td></tr><tr><td>losses_0/clipfrac</td><td>0.05079</td></tr><tr><td>losses_0/entropy</td><td>8.49535</td></tr><tr><td>losses_0/explained_variance</td><td>-0.33749</td></tr><tr><td>losses_0/old_approx_kl</td><td>0.01466</td></tr><tr><td>losses_0/policy_loss</td><td>-0.00737</td></tr><tr><td>losses_0/value_loss</td><td>0.2428</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-river-14</strong> at: <a href='https://wandb.ai/thomas_lautenbacher/moppo_example/runs/tbyoluxs' target=\"_blank\">https://wandb.ai/thomas_lautenbacher/moppo_example/runs/tbyoluxs</a><br/> View project at: <a href='https://wandb.ai/thomas_lautenbacher/moppo_example' target=\"_blank\">https://wandb.ai/thomas_lautenbacher/moppo_example</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240606_144229-tbyoluxs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "wandb.init(project=\"moppo_example\")  # Initialize W&B logging\n",
    "max_iterations = 1\n",
    "start_time = time.time()\n",
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    moppo.train(start_time, iteration, max_iterations)\n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"Iteration {iteration}/{max_iterations} completed.\")\n",
    "\n",
    "envs.close()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MORL_baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
